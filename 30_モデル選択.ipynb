{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情報量基準\n",
    "\n",
    "多変量解析において、しばしば全ての変数を用いるのではなく、何らかの基準に基づき、適切な変数を洗濯したいと考える場合がある。  \n",
    "あるいは、統計モデルの候補の中から適切なモデルを選択したい場合もある。  \n",
    "このような老婆に、尤度とパラメータの数に基づいた「情報量基準」による変数選択法・モデル選択法が提案されている。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 赤池情報量基準\n",
    "\n",
    "情報量基準に代表的なものの一つとして、重回帰分析に限らず、あらゆる統計モデルの選択に幅広く用いられている**赤池情報量基準**(**AIC**)が知られている。  \n",
    "赤池情報量基準は、データへの統計モデルの当てはまりの良さ(尤度の値の大きさ)と統計モデルの簡潔さ(推定するパラメータの少なさ)のバランスをとる統計モデルを選ぶための方法として提案されたものである。\n",
    "あるモデルのAICの値は、そのモデルにおける最大尤度を$L$、推定するパラメータ数を$k$とおくと、\n",
    "$$\n",
    "AIC = -2 \\log L + 2k\n",
    "$$\n",
    "で計算される。\n",
    "統計モデルの候補の中で、AICの値を最小にするモデルを選ぼうというのが赤池情報量基準を用いたモデル選択となる。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重回帰分析におけるAIC\n",
    "\n",
    "個体数n、説明変数の数pの場合の重回帰モデル\n",
    "$$\n",
    "y = X \\beta + \\varepsilon \\quad (\\varepsilon \\sim N(0, \\sigma^2 I_n))\n",
    "$$\n",
    "におけるAICの値を導出してみる。  \n",
    "推定するパラメータの数は、$\\beta$と$\\sigma^2$を合わせて計$p+2$個であるから、AICの値は\n",
    "$$\n",
    "AIC = -2 \\log L+2(p+2) = n (\\log S_e + \\log (\\frac{2 \\pi}{n})+1)+2(p+2)\n",
    "$$\n",
    "と表される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern1 AIC:475.0\n",
      "Pattern2 AIC:472.0\n",
      "Pattern3 AIC:455.0\n",
      "Pattern4 AIC:442.0\n",
      "Pattern5 AIC:444.0\n"
     ]
    }
   ],
   "source": [
    "# ワインデータセットの重回帰分析でAICを確認\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine_data = load_wine()\n",
    "wine_df = pd.DataFrame(data=wine_data.data, columns=wine_data.feature_names)\n",
    "wine_df['class'] = wine_data.target\n",
    "\n",
    "y_col = ['class']\n",
    "y= wine_df[y_col]\n",
    "\n",
    "# 重回帰モデルを作成\n",
    "# pattern1\n",
    "x_pattern1_col = ['alcohol']\n",
    "x = wine_df[x_pattern1_col]\n",
    "model = sm.GLM(y, sm.add_constant(x), family=sm.families.NegativeBinomial())\n",
    "result = model.fit()\n",
    "print(f'Pattern1 AIC:{result.aic.round()}')\n",
    "\n",
    "# pattern2\n",
    "x_pattern2_col = ['malic_acid']\n",
    "x = wine_df[x_pattern2_col]\n",
    "model = sm.GLM(y, sm.add_constant(x), family=sm.families.NegativeBinomial())\n",
    "result = model.fit()\n",
    "print(f'Pattern2 AIC:{result.aic.round()}')\n",
    "\n",
    "# pattern3\n",
    "x_pattern3_col = ['ash','alcalinity_of_ash']\n",
    "x = wine_df[x_pattern3_col]\n",
    "model = sm.GLM(y, sm.add_constant(x), family=sm.families.NegativeBinomial())\n",
    "result = model.fit()\n",
    "print(f'Pattern3 AIC:{result.aic.round()}')\n",
    "\n",
    "# pattern4\n",
    "x_pattern4_col = ['magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins']\n",
    "x = wine_df[x_pattern4_col]\n",
    "model = sm.GLM(y, sm.add_constant(x), family=sm.families.NegativeBinomial())\n",
    "result = model.fit()\n",
    "print(f'Pattern4 AIC:{result.aic.round()}')\n",
    "\n",
    "# pattern5\n",
    "x_pattern5_col = ['color_intensity','hue','od280/od315_of_diluted_wines']\n",
    "x = wine_df[x_pattern5_col]\n",
    "model = sm.GLM(y, sm.add_constant(x), family=sm.families.NegativeBinomial())\n",
    "result = model.fit()\n",
    "print(f'Pattern5 AIC:{result.aic.round()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AICに基づき、Pattern4のモデルを選択する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重回帰分析におけるAICとF検定統計量との関係\n",
    "\n",
    "重回帰分析におけるAICは、$F$検定統計量による変数選択と密接な関係があり、$n$が大きい時、$F$検定統計量が2より大きいかどうかを基準とした変数選択と似た結果を与えることが知られている。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その他の情報量基準\n",
    "\n",
    "AICは大標本の仮定に基づいて導出されているが、標本の大きさが小さい時も、期待平均対数尤度の不偏推定量を与える基準として、**c-AIC**(**AICの有限修正**)が提案されている。  \n",
    "そのほかにも、**MDL**(**最小記述長**というものも提案されている。  \n",
    "中でも、近年、AICの他によく用いられるのは**BIC**(**ベイズ情報量基準**)である。  \n",
    "最大尤度を$L$、推定するパラメータ数を$k$とおくと、\n",
    "$$\n",
    "BIC = -2 \\log L + k \\log n\n",
    "$$\n",
    "で計算される。  \n",
    "AICと比較すると、推定するパラメータの数によるペナルティが$2k$から$k \\log n$に変わっている。  \n",
    "したがって、$n \\geq 8$以上の時により簡潔なモデルを選ぶ傾向にある。  \n",
    "また、近年、AICより好まれている点として、サンプルサイズが$n \\rightarrow \\infty$の時、確率$1$で真のモデルを選択することができることが挙げられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern1 BIC:403.0\n",
      "Pattern2 BIC:386.0\n",
      "Pattern3 BIC:348.0\n",
      "Pattern4 BIC:213.0\n",
      "Pattern5 BIC:224.0\n"
     ]
    }
   ],
   "source": [
    "# ワインデータセットの重回帰分析でBICを確認\n",
    "# pattern1\n",
    "x_pattern1_col = ['alcohol']\n",
    "x = wine_df[x_pattern1_col]\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print(f'Pattern1 BIC:{result.bic.round()}')\n",
    "\n",
    "# pattern2\n",
    "x_pattern2_col = ['malic_acid']\n",
    "x = wine_df[x_pattern2_col]\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print(f'Pattern2 BIC:{result.bic.round()}')\n",
    "\n",
    "# pattern3\n",
    "x_pattern3_col = ['ash','alcalinity_of_ash']\n",
    "x = wine_df[x_pattern3_col]\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print(f'Pattern3 BIC:{result.bic.round()}')\n",
    "\n",
    "# pattern4\n",
    "x_pattern4_col = ['magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins']\n",
    "x = wine_df[x_pattern4_col]\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print(f'Pattern4 BIC:{result.bic.round()}')\n",
    "\n",
    "# pattern5\n",
    "x_pattern5_col = ['color_intensity','hue','od280/od315_of_diluted_wines']\n",
    "x = wine_df[x_pattern5_col]\n",
    "model = sm.OLS(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print(f'Pattern5 BIC:{result.bic.round()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BICに基づき、Pattern4のモデルを選択する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クロスバリデーション\n",
    "\n",
    "統計解析手法を用いてデータを分析したときに、得られたモデルがどの程度の精度をもつかを調べたい場合がある。  \n",
    "**クロスバリデーション**(**交差検証**)は、各群のデータを$K$分割し、そのうちの1セットをテスト用として外しておき、$K-1$セットのデータで判別関数を求め、テスト用の1セットのデータで誤判別率を推定する、ということをテスト用として残す1セットの選択の$K$通り全ての場合を調べ、全ての場合の誤判別率の平均をとる、という方法である。  \n",
    "特に、$K=n$($n$は標本の大きさ)とした場合のクロスバリデーションは**Leave-one-out法**と呼ばれる。  \n",
    "クロスバリデーションは、変数選択やモデル選択の基準としてもよく用いられる。  \n",
    "統計解析手法全般において、データを分析する際、複雑なモデルほど**学習データ**に対する適合はよくなるが、一方、将来のデータに対する予測精度はかえって落ちることが生じやすくなる。(**過学習**、**過適合**と呼ぶ)  \n",
    "そこで、将来のデータを模擬したテストデータで精度を調べるために、クロスバリデーションに基づいて、モデル選択を行うことがある。  \n",
    "学習データとテストデータの分割を変えて何度も解析を行うという手順になるため、計算量は大きくなることに注意が必要である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=5 scores: [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average score: 0.9266666666666665\n",
      "K=n(Leave-one-out scores): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Average score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# irisデータで実践\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=5) # K=5分割で実行する\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=kfold)\n",
    "print(f'K=5 scores: {scores}')\n",
    "print(f'Average score: {np.mean(scores)}')\n",
    "\n",
    "lookfold = KFold(n_splits=len(iris.data)) # K=n分割で実行する\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=lookfold)\n",
    "print(f'K=n(Leave-one-out scores): {scores}')\n",
    "print(f'Average score: {np.mean(scores)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過学習の問題\n",
    "\n",
    "たまたま得られたデータに合わせすぎると、かえって母集団全体に対する判別精度は落ちることが十分にありうる。  \n",
    "また、複雑な判別関数やモデルを作成すると、意味づけを行うことが難しく、解析結果のブラックボックス化を生む。  \n",
    "このような問題をしばしば**過学習の問題**と呼び、これを避けるために、統計解析では、パラメータ数が大きすぎるモデルや、データ数に近いパラメータ数のモデルを用いることを避け、データの当てはまりの良さとモデルの簡潔さのバランスを取ることが良いとされることが多い。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31764a0ab3329e725d74bc2166eb119537181bd6cc650e6bbc5c27684234dfe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
